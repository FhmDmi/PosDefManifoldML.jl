<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Elastic-Net Logistic Regression ¬∑ PosDefManifoldML</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../"><img class="logo" src="../assets/logo.png" alt="PosDefManifoldML logo"/></a><h1>PosDefManifoldML</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">PosDefManifoldML Documentation</a></li><li><a class="toctext" href="../tutorial/">Tutorial</a></li><li><a class="toctext" href="../MainModule/">Main Module</a></li><li><a class="toctext" href="../tools/">Tools</a></li><li><span class="toctext">ML Models: PD Manifold</span><ul><li><a class="toctext" href="../mdm/">Minimum Distance to Mean</a></li></ul></li><li><span class="toctext">ML Models: PD Tangent Space</span><ul><li class="current"><a class="toctext" href>Elastic-Net Logistic Regression</a><ul class="internal"></ul></li><li><a class="toctext" href="../svm/">Support-Vector Machine</a></li></ul></li><li><a class="toctext" href="../cv/">fit, predict, cv</a></li><li><a class="toctext" href="../contribute/">How to contribute</a></li></ul></nav><article id="docs"><header><nav><ul><li>ML Models: PD Tangent Space</li><li><a href>Elastic-Net Logistic Regression</a></li></ul><a class="edit-page" href="https://github.com/Marco-Congedo/PosDefManifoldML.jl/blob/master/docs/src/enlr.md"><span class="fa">ÔÇõ</span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Elastic-Net Logistic Regression</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="enlr.jl-1" href="#enlr.jl-1">enlr.jl</a></h1><p>This unit implements the <strong>elastic net logistic regression (ENLR)</strong> machine learning model on the tangent space for symmetric positive definite (SDP) matrices, <em>i.e.</em>, real PD matrices. This model features two hyperparameters: a user-defined <strong>alpha</strong> hyperparameter, in range <span>$[0, 1]$</span>, where <span>$Œ±=0$</span> allows a pure <strong>Ridge</strong> LR model and <span>$Œ±=1$</span> a pure <strong>lasso</strong> LR model and the <strong>lambda</strong> (regularization) hyperparameter. When the model is fitted, we can request to find the optimal lambda hyperparameter for the given training data using cross-validation and/or to find the regularization path.</p><p>The lasso model (default) has enjoyed popularity in the field of <em>brain-computer interaces</em> due to the <a href="http://alexandre.barachant.org/challenges/">winning score</a> obtained in six international data classification competitions.</p><p>The ENLR model is implemented using the Julia <a href="https://github.com/JuliaStats/GLMNet.jl">GLMNet.jl</a> package. See <a href="../#-1">üéì</a> for resources on GLMNet.jl and learn how to use purposefully this model.</p><p>The <strong>fit</strong>, <strong>predict</strong> and <strong>cvAcc</strong> functions for the ENRL models are reported in the <a href="../cv/#cv.jl-1">cv.jl</a> unit, since those are homogeneous across all machine learning models. Here it is reported the <a href="#PosDefManifoldML.ENLRmodel"><code>ENLRmodel</code></a> abstract type and the <a href="#PosDefManifoldML.ENLR"><code>ENLR</code></a> structure.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifoldML.ENLRmodel" href="#PosDefManifoldML.ENLRmodel"><code>PosDefManifoldML.ENLRmodel</code></a> ‚Äî <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">abstract type ENLRmodel&lt;:TSmodel end</code></pre><p>Abstract type for <strong>Elastic Net Logistic Rgression (ENLR)</strong> machine learning models. See <a href="../MainModule/#MLmodel-1">MLmodel</a>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifoldML.jl/blob/317481d8897a694611a018125c99e1c2cb643e1b/src/enlr.jl#L14-L21">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifoldML.ENLR" href="#PosDefManifoldML.ENLR"><code>PosDefManifoldML.ENLR</code></a> ‚Äî <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">mutable struct ENLR &lt;: ENLRmodel
    metric      :: Metric = Fisher;
    alpha       :: Real = 1.0
    standardize :: Bool
    intercept   :: Bool
	meanISR     :: Union{‚ÑçVector, Nothing}
	vecRange    :: UnitRange
    featDim     :: Int
	# GLMNet Models
    path        :: GLMNet.GLMNetPath
    cvŒª         :: GLMNet.GLMNetCrossValidation
    best        :: GLMNet.GLMNetPath
end</code></pre><p>ENLR machine learning models are incapsulated in this mutable structure. Fields:</p><p><code>.metric</code>, of type <a href="https://marco-congedo.github.io/PosDefManifold.jl/dev/MainModule/#Metric::Enumerated-type-1">Metric</a>, is the metric that will be adopted to compute the mean used as base-point for tangent space projection. By default the Fisher metric is adopted. See <a href="../mdm/#mdm.jl-1">mdm.jl</a> for the available metrics. If the data used to train the model are not positive definite matrices, but Euclidean feature vectors, the <code>.metric</code> field has no use.</p><p><code>.alpha</code> is the hyperparameter in <span>$[0, 1]$</span> trading-off the <strong>elestic-net model</strong>. <span>$Œ±=0$</span> requests a pure <strong>ridge</strong> model and <span>$Œ±=1$</span> a pure <strong>lasso</strong> model. By default, <span>$Œ±=1$</span> is specified (lasso model). This argument is usually passed as parameter to the <a href="../cv/#StatsBase.fit"><code>fit</code></a> function, defaulting therein to <span>$Œ±=1$</span> too. See the examples here below.</p><p>All other fields do not correspond to arguments passed upon creation of the model by the default creator. Instead, they are filled later when a model is created by the <a href="../cv/#StatsBase.fit"><code>fit</code></a> function:</p><p>For the content of fields <code>standardize</code>, <code>intercept</code>, <code>meanISR</code> and <code>vecRange</code>, please see the documentation of the <a href="../cv/#StatsBase.fit"><code>fit</code></a> function.</p><p>if the data used to train the model are positive definite matrices, <code>.featDim</code> is the length of the vectorized tangent vectors. This is given by <span>$n(n+1)√∑2$</span> (integer division), where <span>$n$</span> is the dimension of the original PD matrices on which the model is applied once they are mapped onto the tangent space. If feature vectors are used to train the model, <code>.featDim</code> is the length of these vectors. If for fitting the model you have provided an optional keyword argument <code>vecRange</code>, <code>.featDim</code> will be reduced accordingly.</p><p><code>.path</code> is an instance of the following <code>GLMNetPath</code> structure of the <a href="https://github.com/JuliaStats/GLMNet.jl">GLMNet.jl</a> package. It holds the regularization path that is created when the <a href="../cv/#StatsBase.fit"><code>fit</code></a> function is invoked with optional keyword parameter <code>fitType</code> = <code>:path</code> or = <code>:all</code>:</p><pre><code class="language-none">struct GLMNetPath{F&lt;:Distribution}
    family::F                        # Binomial()
    a0::Vector{Float64}              # intercept values for each solution
    betas::CompressedPredictorMatrix # coefficient values for each solution
    null_dev::Float64                # Null deviance of the model
    dev_ratio::Vector{Float64}       # R^2 values for each solution
    lambda::Vector{Float64}          # lambda values for each solution
    npasses::Int                     # actual number of passes over the
                                     # data for all lamda values
end</code></pre><p><code>.cvŒª</code> is an instance of the following <code>GLMNetCrossValidation</code> structure of the <a href="https://github.com/JuliaStats/GLMNet.jl">GLMNet.jl</a> package. It holds information about the cross-validation used for estimating the optimal lambda hyperparameter by the <a href="../cv/#StatsBase.fit"><code>fit</code></a> function when this is invoked with optional keyword parameter <code>fitType</code> = <code>:best</code> (default) or = <code>:all</code>:</p><pre><code class="language-none">struct GLMNetCrossValidation
    path::GLMNetPath            # the cv path
    nfolds::Int                 # the number of folds for the cv
    lambda::Vector{Float64}     # lambda values for each solution
    meanloss::Vector{Float64}   # mean loss for each solution
    stdloss::Vector{Float64}    # standard deviation of the mean losses
end</code></pre><p><code>.best</code> is an instance of the <code>GLMNetPath</code> structure (see above). It holds the model with the optimal lambda parameter found by cross-validation that is created by default when the <a href="../cv/#StatsBase.fit"><code>fit</code></a> function is invoked.</p><p><strong>Examples</strong>:</p><pre><code class="language-none"># Note: creating models with the default creator is possible,
# but not useful in general.

using PosDefManifoldML

# create an empty lasso model
m = ENLR(Fisher)

# since the Fisher metric is the default metric,
# this is equivalent to
m = ENLR()

# create an empty ridge model using the logEuclidean metric
m = ENLR(logEuclidean; alpha=0)

# Empty models can be passed as first argument of the `fit` function
# to fit a model. For instance, this will fit a ridge model of the same
# kind of `m` and put the fitted model in `m1`:
m1=fit(m, PTr, yTr)

# in general you don&#39;t need this machinery for fitting a model,
# since you can specify a model by creating one on the fly:
m2=fit(ENLR(logEuclidean; alpha=0), PTr, yTr)

# which is equivalent to
m2=fit(ENLR(logEuclidean), PTr, yTr; alpha=0)

# note that, albeit model `m` has been created as a ridge model,
# you have passed `m` and overwritten the `alpha` hyperparameter.
# The metric, instead, cannot be overwritten.
</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifoldML.jl/blob/317481d8897a694611a018125c99e1c2cb643e1b/src/enlr.jl#L25-L155">source</a></section><footer><hr/><a class="previous" href="../mdm/"><span class="direction">Previous</span><span class="title">Minimum Distance to Mean</span></a><a class="next" href="../svm/"><span class="direction">Next</span><span class="title">Support-Vector Machine</span></a></footer></article></body></html>
